{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import git.repo\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.datasets\n",
    "import wandb\n",
    "import wandb.sdk\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "GIT_ROOT = pathlib.Path(\n",
    "    str(git.repo.Repo(\".\", search_parent_directories=True).working_tree_dir)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(str(GIT_ROOT))\n",
    "from src.ax.attack.FastAutoAttack import FastAutoAttack\n",
    "from src.ax.attack.FastPGD import FastPGD\n",
    "from src.ax.models import wrn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = torchvision.datasets.MNIST(\n",
    "    root=\"/var/tmp/scratch\",\n",
    "    train=False,\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1, 28, 28]) torch.Size([10000])\n",
      "torch.float32 torch.int64\n",
      "tensor(0.) tensor(1.)\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "xs_test = (mnist_test.data / 255.0).reshape(-1, 1, 28, 28)\n",
    "ys_test  = mnist_test.targets\n",
    "print(xs_test.shape, ys_test.shape)\n",
    "print(xs_test.dtype, ys_test.dtype)\n",
    "print(xs_test.min(), xs_test.max())\n",
    "print(ys_test.min(), ys_test.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nat (orig) acc: 0.9943999997138976\n",
      "Adv (orig) acc: 0.973100000667572\n"
     ]
    }
   ],
   "source": [
    "# Run https://wandb.ai/data-frugal-learning/adv-train/runs/1omt9pgp\n",
    "api = wandb.Api()\n",
    "run: wandb.sdk.wandb_run.Run = api.run(\n",
    "    \"data-frugal-learning/adv-train/1omt9pgp\"\n",
    ")\n",
    "\n",
    "print(\"Nat (orig) acc:\", run.summary[\"test_orig_acc_nat\"])\n",
    "print(\"Adv (orig) acc:\", run.summary[\"test_orig_acc_adv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = (\n",
    "    pathlib.Path(run.config[\"wandb_dir\"])\n",
    "    / \"wandb\"\n",
    "    / \"run-20221006_210854-1omt9pgp\"\n",
    "    / \"files\"\n",
    "    / \"model.ckpt\"\n",
    ")\n",
    "\n",
    "model = wrn.get_mup_wrn(\n",
    "    depth=run.config[\"depth\"],\n",
    "    width=run.config[\"width\"],\n",
    "    num_classes=10,\n",
    "    mean=(0.5,),\n",
    "    std=(1.0,),\n",
    "    num_input_channels=1,\n",
    ")\n",
    "model = model.to(memory_format=torch.channels_last)  # type: ignore\n",
    "\n",
    "# Load checkpoint\n",
    "model.load_state_dict(torch.load(ckpt_path))\n",
    "model.eval().cuda();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate natural accuracy (sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c841c46434e34d98acf8be78d892ee55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nat (orig) acc: 0.9944\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(\n",
    "        DataLoader(TensorDataset(xs_test, ys_test), batch_size=256)\n",
    "    ):\n",
    "        logits = model(images.cuda())\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        n_correct += (preds == labels.cuda()).sum().item()\n",
    "\n",
    "print(f\"Nat (orig) acc: {n_correct / len(xs_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate autoattack accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f983a2ab2cd14e4287a6e4ae053fe5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adv (orig) acc: 0.9614\n"
     ]
    }
   ],
   "source": [
    "attack = FastAutoAttack(model, eps=0.3)\n",
    "n = len(xs_test)\n",
    "\n",
    "n_correct = 0\n",
    "for xs, ys in tqdm(\n",
    "    DataLoader(TensorDataset(xs_test[:n], ys_test[:n]), batch_size=512)\n",
    "):\n",
    "    xs_adv = attack(xs.half().cuda(), ys.cuda())\n",
    "\n",
    "    logits = model(xs_adv)\n",
    "    preds = logits.argmax(dim=-1)\n",
    "    n_correct += (preds == ys.cuda()).sum().item()\n",
    "\n",
    "print(f\"Adv (orig) acc: {n_correct / n:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate 40 step pgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b0c112a153405b90d822619ead2dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9732 0.9698 0.9685 0.9675 0.9664 0.9658 0.9655 0.9654 0.9649 0.9649]\n"
     ]
    }
   ],
   "source": [
    "attack = FastPGD(\n",
    "    model,\n",
    "    eps=0.3,\n",
    "    alpha=0.3 / 40 * 2.3,\n",
    "    steps=40,\n",
    "    random_start=True,\n",
    ")\n",
    "n_reps = 10\n",
    "\n",
    "n = len(xs_test)\n",
    "\n",
    "n_corrects = np.array([0 for _ in range(n_reps)])\n",
    "for xs, ys in tqdm(\n",
    "    DataLoader(TensorDataset(xs_test[:n], ys_test[:n]), batch_size=512)\n",
    "):\n",
    "    failures = torch.zeros_like(ys, dtype=torch.bool, device=\"cuda\")\n",
    "    for i in range(n_reps):\n",
    "        xs_adv = attack(xs.half().cuda(), ys.cuda())\n",
    "\n",
    "        logits = model(xs_adv)\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        failures = failures | (preds != ys.cuda())\n",
    "\n",
    "        n_corrects[i] += (~failures).sum().item()\n",
    "\n",
    "print(n_corrects / n)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('scaling-v2-tmp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47ef31053d8b728266120e9d84fd013ec3b97028489e5d749b36c7d18b82d09d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
