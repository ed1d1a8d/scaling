{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has some code for querying wandb runs.\n",
    "\n",
    "Potential use:\n",
    "Pull failed runs and collect run commands\n",
    "for relaunching with `src.slurm.manual_launch`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import git.repo\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import wandb.apis.public\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "GIT_ROOT = pathlib.Path(\n",
    "    str(git.repo.Repo(\".\", search_parent_directories=True).working_tree_dir)\n",
    ")\n",
    "sys.path.append(str(GIT_ROOT))\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query wandb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api(timeout=30)\n",
    "runs: list[wandb.apis.public.Run] = api.runs(\n",
    "    f\"data-frugal-learning/finetune\",\n",
    "    filters={\n",
    "        \"$and\": [\n",
    "            {\"tags\": {\"$in\": [\"finetune-sweep-freeze-v1\"]}},\n",
    "        ]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [r for r in runs if r.state not in (\"finished\", \"running\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m src.pretrain.finetune --dataset_cfg cifar10 --embedder_cfg openai_clip --embedder_cfg.id openai/ViT-B/16 --init_with_trained_linear_probe True --batch_size 50 --seed 0 --n_train 50000 --n_layers_to_freeze 9 --tags finetune-sweep-freeze-v1 --n_val_override 10000\n",
      "python -m src.pretrain.finetune --dataset_cfg cifar10 --embedder_cfg openai_clip --embedder_cfg.id openai/ViT-B/16 --init_with_trained_linear_probe True --batch_size 50 --seed 0 --n_train 10500 --n_layers_to_freeze 1 --tags finetune-sweep-freeze-v1 --n_val_override 10000\n",
      "python -m src.pretrain.finetune --dataset_cfg cifar10 --embedder_cfg openai_clip --embedder_cfg.id openai/ViT-B/16 --init_with_trained_linear_probe True --batch_size 50 --seed 0 --n_train 12500 --n_layers_to_freeze 6 --tags finetune-sweep-freeze-v1 --n_val_override 10000\n",
      "python -m src.pretrain.finetune --dataset_cfg cifar10 --embedder_cfg openai_clip --embedder_cfg.id openai/ViT-B/16 --init_with_trained_linear_probe True --batch_size 50 --seed 0 --n_train 10500 --n_layers_to_freeze 10 --tags finetune-sweep-freeze-v1 --n_val_override 10000\n",
      "python -m src.pretrain.finetune --dataset_cfg cifar10 --embedder_cfg openai_clip --embedder_cfg.id openai/ViT-B/16 --init_with_trained_linear_probe True --batch_size 50 --seed 0 --n_train 10250 --n_layers_to_freeze 2 --tags finetune-sweep-freeze-v1 --n_val_override 10000\n",
      "python -m src.pretrain.finetune --dataset_cfg cifar10 --embedder_cfg openai_clip --embedder_cfg.id openai/ViT-B/16 --init_with_trained_linear_probe True --batch_size 50 --seed 0 --n_train 10500 --n_layers_to_freeze 0 --tags finetune-sweep-freeze-v1 --n_val_override 10000\n",
      "python -m src.pretrain.finetune --dataset_cfg cifar10 --embedder_cfg openai_clip --embedder_cfg.id openai/ViT-B/16 --init_with_trained_linear_probe True --batch_size 50 --seed 0 --n_train 10050 --n_layers_to_freeze 6 --tags finetune-sweep-freeze-v1 --n_val_override 10000\n",
      "python -m src.pretrain.finetune --dataset_cfg cifar10 --embedder_cfg openai_clip --embedder_cfg.id openai/ViT-B/16 --init_with_trained_linear_probe True --batch_size 50 --seed 0 --n_train 10100 --n_layers_to_freeze 4 --tags finetune-sweep-freeze-v1 --n_val_override 10000\n",
      "python -m src.pretrain.finetune --dataset_cfg cifar10 --embedder_cfg openai_clip --embedder_cfg.id openai/ViT-B/16 --init_with_trained_linear_probe False --batch_size 50 --seed 0 --n_train 10100 --n_layers_to_freeze 13 --tags finetune-sweep-freeze-v1 --n_val_override 10000\n",
      "python -m src.pretrain.finetune --dataset_cfg cifar10 --embedder_cfg openai_clip --embedder_cfg.id openai/ViT-B/16 --init_with_trained_linear_probe False --batch_size 50 --seed 0 --n_train 10050 --n_layers_to_freeze 15 --tags finetune-sweep-freeze-v1 --n_val_override 10000\n"
     ]
    }
   ],
   "source": [
    "for r in runs:\n",
    "    if \"NODE_FAILURE\" in r.tags:\n",
    "        continue\n",
    "\n",
    "    print(\" \".join(utils.get_run_command(r)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scaling-v3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5883dc9b52c0607acbaf60735ab064fedb4eca077fef8025b9dfd3c924209b4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
