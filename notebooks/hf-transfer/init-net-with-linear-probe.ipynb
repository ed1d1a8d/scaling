{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to initialize an embedding network with a trained linear probe."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import git.repo\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "GIT_ROOT = pathlib.Path(\n",
    "    str(git.repo.Repo(\".\", search_parent_directories=True).working_tree_dir)\n",
    ")\n",
    "sys.path.append(str(GIT_ROOT))\n",
    "\n",
    "from src.pretrain import finetune, gen_embeddings\n",
    "from src.pretrain.datasets.embedding import EmbeddingDataset\n",
    "from src.pretrain.datasets.vision import cifar10, imagenette, svhn\n",
    "from src.pretrain.models.vision import laion_clip, msft_beit, openai_clip\n",
    "from src.pretrain.probes import fc_probe, linear_probe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load network and train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "dataset_cfg = cifar10.CIFAR10()\n",
    "embedder_cfg = openai_clip.OpenaiClipConfig(id=\"openai/ViT-B/16\")\n",
    "finetune_cfg = finetune.Config(\n",
    "    embedder_cfg=embedder_cfg, dataset_cfg=dataset_cfg\n",
    ")\n",
    "\n",
    "embedder = embedder_cfg.get_model().float()\n",
    "# ds_train = torch.utils.data.Subset( # type: ignore\n",
    "#     dataset_cfg.get_train_ds(embedder.preprocess),\n",
    "#     indices=range(1000),  # to make testing faster\n",
    "# )\n",
    "ds_train, _, _ = torch.utils.data.random_split(\n",
    "    dataset_cfg.get_train_ds(embedder.preprocess),\n",
    "    [1000, 10000, 39000],\n",
    ")\n",
    "ds_test = dataset_cfg.get_test_ds(embedder.preprocess)\n",
    "model = (\n",
    "    fc_probe.FCProbeConfig(n_layers=1, n_classes=10)\n",
    "    .get_fc_probe(embedder)\n",
    "    .cuda()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute baseline accuracy of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e9d53add6e416ea469968aa456e61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'acc': WBMetric(data=0.09580000004768371, summary='max'),\n",
       " 'loss': WBMetric(data=2.3757041038513185, summary='min')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "test_dict, _ = finetune.evaluate(\n",
    "    model=model,\n",
    "    loader=finetune_cfg.get_loader(ds_test, eval_mode=True),\n",
    "    cfg=finetune_cfg,\n",
    ")\n",
    "test_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify model to have optimal probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8498dcecdf47ceafd6e6555e943883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W] [19:15:29.152145] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n",
      "Linear probe results:\n",
      "acc: 1.0\n",
      "xent_orig: 0.00097038585\n",
      "xent: -0.0\n"
     ]
    }
   ],
   "source": [
    "sub_eds, clf = finetune.init_model_with_trained_linear_probe(\n",
    "    model=model,\n",
    "    ds=ds_train,\n",
    "    cfg=finetune_cfg,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d8cf84fa994f60b9960a241a146371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'acc': WBMetric(data=0.9365000004768371, summary='max'),\n",
       " 'loss': WBMetric(data=0.24160788896083832, summary='min')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now compute resulting accuracy\n",
    "model.eval()\n",
    "test_dict, _ = finetune.evaluate(\n",
    "    model=model,\n",
    "    loader=finetune_cfg.get_loader(ds_test, eval_mode=True),\n",
    "    cfg=finetune_cfg,\n",
    ")\n",
    "test_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to pure linear probe baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 512), (10000, 512), dtype('float32'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_cfg = gen_embeddings.Config(\n",
    "    dataset_cfg=dataset_cfg,\n",
    "    embedder_cfg=embedder_cfg,\n",
    ")\n",
    "eds = EmbeddingDataset.load_from_file(embedding_cfg.full_save_path).astype(\n",
    "    np.float32\n",
    ")\n",
    "\n",
    "eds.xs_train.shape, eds.xs_test.shape, eds.xs_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9363999962806702"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(eds.xs_test, eds.ys_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare decision function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9441c48758504b3ba5ba68f519cf0c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding comparison:\n",
      "[[ 0.77331966 -0.29994226  0.07011063 ...  0.19855547  0.48564512\n",
      "   0.08899247]\n",
      " [ 0.50367385 -1.0752835   0.0752296  ...  0.24002843  0.15829396\n",
      "   0.09126556]]\n",
      "[[ 0.7758789  -0.30029297  0.06982422 ...  0.19909668  0.48583984\n",
      "   0.08843994]\n",
      " [ 0.50341797 -1.0722656   0.0770874  ...  0.23986816  0.15856934\n",
      "   0.09106445]]\n"
     ]
    }
   ],
   "source": [
    "# EDS_NEW is with a new conda environment and possible new cuda version.\n",
    "eds_new = gen_embeddings.embed_dataset(\n",
    "    model.embedder,\n",
    "    ds=torch.utils.data.Subset(\n",
    "        dataset_cfg.get_test_ds(model.embedder.preprocess),\n",
    "        indices=range(2),\n",
    "    ),\n",
    "    cfg=gen_embeddings.Config(embedder_cfg=embedder_cfg, dataset_cfg=dataset_cfg),\n",
    ")\n",
    "\n",
    "print(\"Embedding comparison:\")\n",
    "print(eds_new[0][:2])\n",
    "print(eds.xs_test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding comparison:\n",
      "[[ 0.77331966 -0.29994226  0.07011063 ...  0.19855547  0.48564512\n",
      "   0.08899247]\n",
      " [ 0.50367385 -1.0752835   0.0752296  ...  0.24002843  0.15829396\n",
      "   0.09126556]]\n",
      "[[ 0.7758789  -0.30029297  0.06982422 ...  0.19909668  0.48583984\n",
      "   0.08843994]\n",
      " [ 0.50341797 -1.0722656   0.0770874  ...  0.23986816  0.15856934\n",
      "   0.09106445]]\n",
      "\n",
      "Logit comparison:\n",
      "[[-3.5558755  -2.8956425  -0.860857    9.480637   -3.1567836   5.441544\n",
      "   3.006999   -2.4137075  -2.6379287  -3.4146023 ]\n",
      " [-0.867033    0.7218502  -0.24550343  1.3061492  -5.9057727  -9.009769\n",
      "  -4.9407964  -2.07026    17.649624    2.373362  ]]\n",
      "[[-3.5421736  -2.8947928  -0.8484082   9.486113   -3.1623018   5.4385223\n",
      "   3.0049486  -2.4247503  -2.6465964  -3.4168882 ]\n",
      " [-0.85966563  0.7409808  -0.27235842  1.2886996  -5.902449   -8.9882965\n",
      "  -4.910681   -2.0559483  17.616325    2.3548064 ]]\n"
     ]
    }
   ],
   "source": [
    "model = model.train()\n",
    "for imgs, _ in dataclasses.replace(finetune_cfg, eval_batch_size=2).get_loader(\n",
    "    ds_test, eval_mode=True\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.embedder.get_embeddings(imgs.cuda())\n",
    "        logits = model(imgs.cuda())\n",
    "    break\n",
    "\n",
    "print(\"Embedding comparison:\")\n",
    "print(embeddings.cpu().numpy())\n",
    "print(eds.xs_test[:2])\n",
    "print()\n",
    "print(\"Logit comparison:\")\n",
    "print(logits.cpu().numpy())\n",
    "print(clf.decision_function(eds.xs_test[:2]).T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scaling-v3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5883dc9b52c0607acbaf60735ab064fedb4eca077fef8025b9dfd3c924209b4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
